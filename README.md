# MCP WORKSHOP

Welcome to the **Model Context Protocol (MCP) Workshop**! This is a live, iterative tutorial between me (Sean) and ChatGPT — building understanding from first principles and implementing a conceptual prototype in JavaScript step by step.

## 🚀 Goal

Learn and build a conceptual prototype of the Model Context Protocol (MCP) using JavaScript. We’ll simulate how LLMs can interact with tools, external data sources, and memory through a structured protocol.

## 📦 Versions

### ✅ Version 1.0.0 (Locked)

To check out the original minimal working prototype:

```bash
git checkout v1.0.0
```

Covered in v1:

- Static regex-based tool detection
- Dynamic tool registry (`registry.js`)
- Tools: `calculator`, `time`, `diceRoll`
- Zod-based schema validation for input/output
- Structured tool invocation responses
- CLI for listing tools: `npm run tools`
- Logging and tracing of tool usage

---

### ✅ Version 2.0.0 (Latest)

To use the latest version:

```bash
git checkout main
npm install
npm start
```

Added in v2:

- 🧠 `planTool()` uses GPT-4 to route user prompts to tools
- 🧪 `scripts/testPlanner.js` lets you try LLM-driven planning via `npm run plan`
- 🧰 `handleMessage()` falls back to the LLM if no tool is matched
- 🔁 Tool output is passed back to GPT-4 via `finalReply()`
- 💬 Final user-facing response is generated by the LLM

v2 completes the full reasoning loop:  
**LLM → tool → LLM**

---

## 📚 What is MCP?

MCP (Model Context Protocol) is an open standard introduced by Anthropic in November 2024. It provides a structured way for LLMs to:

- Access and query external tools
- Retrieve and store context
- Compose workflows involving multiple steps
- Maintain a consistent schema for structured communication

## 🧠 Key Concepts We’ll Explore

- Messages and structured communication
- Tool use and invocation
- External context (retrieval, storage, reasoning)
- Schema design
- Simulated agents and tool responses

## 🛠 Stack

We’ll use:

- JavaScript (Node.js)
- JSON for message structure
- Zod for schema validation
- OpenAI’s GPT-4 for planning
- Simple local mocks for tools and memory

## 🧩 Structure

- `src/`
  - `index.js` — Entry point for the workshop
  - `messages/` — Simulated message handling and agent logic
  - `tools/` — Mock external tools (e.g., calculator, time, dice, registry)
  - `llm/` — Planner + final response generation using OpenAI
  - `memory/` — Contextual storage/retrieval (TBD)
  - `schemas/` — Definitions for message formats (TBD)
  - `tracing/` — Logs structured tool usage to simulate MCP-style traceability
- `scripts/`
  - `listTools.js` — Lists available tool cards
  - `testPlanner.js` — Interactively test LLM tool planning via CLI
- `.env` — Holds your `OPENAI_API_KEY`
- `README.md` — This file

## 🏁 How to Start

```bash
npm install
npm start
```

To list available tools:

```bash
npm run tools
```

To test LLM tool planning:

```bash
npm run plan
```

---

## ✅ Progress So Far

- ✔️ Created initial `README.md`
- ✔️ Set up ESLint and Prettier for 2-space indentation and no semicolons
- ✔️ Built regex-matching tool agent with structured logging
- ✔️ Built MCP-style tool cards with Zod input/output schemas
- ✔️ CLI interface for listing tools and testing inputs
- ✔️ Introduced LLM planner using GPT-4 (`planTool.js`)
- ✔️ Tool fallback routing to planner when regex fails
- ✔️ Final response generation using GPT-4 (`finalReply.js`)
- ✔️ Full loop: **LLM → tool → LLM**

Next up: explore memory, multi-step chains, and agent reasoning paths.
